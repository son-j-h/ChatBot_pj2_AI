from dotenv import load_dotenv

load_dotenv()

from langchain.chains import RetrievalQA
from langchain_openai import OpenAI, OpenAIEmbeddings
from langchain_chroma import Chroma

llm = OpenAI(temperature=0)


def load_vector_db():
    embeddings = OpenAIEmbeddings()
    vector_db = Chroma(
        persist_directory="C:/Users/user/IdeaVsProject/my_chatbot_project/my_rag_db",
        embedding_function=embeddings,
    )
    return vector_db


vector_db = load_vector_db()
qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=vector_db.as_retriever())


def answer(user_input: str):
    # ëª¨ë“  ì§ˆë¬¸ì„ ë²¡í„° DB + LLM ì§ˆì˜ì‘ë‹µìœ¼ë¡œ ì²˜ë¦¬
    response = qa_chain.invoke({"query": user_input})
    print("ğŸ¤– ì¦ëª…ì„œ ë°œê¸‰ ì•ˆë‚´ì…ë‹ˆë‹¤:\n")
    print(response["result"])
